{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow liveness local & remote training  \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments.  This can speed up iterative testing and debugging while using the same familiar Python SDK interface.  Just change your estimator's `instance_type` to `local` (or `local_gpu` if you're using an ml.p2 or ml.p3 notebook instance).\n",
    "\n",
    "In order to use this feature, you'll need to install docker-compose (and nvidia-docker if training with a GPU).\n",
    "\n",
    "**Note: you can only run a single local notebook at one time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow, MXNet, PyTorch. This tutorial focuses on how to create a convolutional neural network model to train the [NUAA dataset](http://parnec.nuaa.edu.cn/_upload/tpl/02/db/731/template731/pages/xtan/NUAAImposterDB_download.html) using **Tensorflow in local mode**.\n",
    "\n",
    "### Set up the environment\n",
    "\n",
    "This notebook was created and tested on a single ml.p2.xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: awscli in /opt/conda/envs/liveness/lib/python3.6/site-packages (1.22.10)\n",
      "Requirement already satisfied: colorama<0.4.4,>=0.2.5 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from awscli) (0.4.3)\n",
      "Requirement already satisfied: PyYAML<5.5,>=3.10 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from awscli) (5.4.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from awscli) (0.15.2)\n",
      "Requirement already satisfied: botocore==1.23.10 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from awscli) (1.23.10)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from awscli) (4.7)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from awscli) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from botocore==1.23.10->awscli) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from botocore==1.23.10->awscli) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from botocore==1.23.10->awscli) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.23.10->awscli) (1.15.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from rsa<4.8,>=3.1.2->awscli) (0.4.8)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: boto3 in /opt/conda/envs/liveness/lib/python3.6/site-packages (1.20.10)\n",
      "Requirement already satisfied: sagemaker in /opt/conda/envs/liveness/lib/python3.6/site-packages (2.69.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.10 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from boto3) (1.23.10)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from boto3) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from botocore<1.24.0,>=1.23.10->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from botocore<1.24.0,>=1.23.10->boto3) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.10->boto3) (1.15.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (1.1.5)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (20.9)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: attrs in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from sagemaker) (3.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /opt/conda/envs/liveness/lib/python3.6/site-packages (from pathos->sagemaker) (0.70.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install awscli --upgrade\n",
    "!pip install boto3 sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "instance_type = \"local\"\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name sagemaker_execution to get Role path.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the NUAA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_train_data\n",
      "Read preprocessed data from cache file: train.pkl\n",
      "process_test_data\n",
      "Read preprocessed data from cache file: test.pkl\n",
      "There are 2792 training examples \n",
      "There are 699 validation examples\n",
      "There are 9123 testing examples\n",
      "Image data shape is (64, 64)\n",
      "There are 2 classes\n"
     ]
    }
   ],
   "source": [
    "#!pygmentize utils_tf.py\n",
    "%run utils_tf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# get some random training images\n",
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "#print(' '.join('%9s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train locally\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-22 00:27:46.314902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "tensorflow version: 2.4.1\n",
      "(2792, 64, 64) (2792,) (699, 64, 64) (699,)\n",
      "channels_last\n",
      "x_train shape: (2792, 64, 64, 1)\n",
      "2792 train samples\n",
      "699 test samples\n",
      "2021-11-22 00:27:48.268203: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-22 00:27:48.269204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-22 00:27:48.280949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 00:27:48.281846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.6575GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2021-11-22 00:27:48.281899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-22 00:27:48.284615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-11-22 00:27:48.284688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-11-22 00:27:48.285582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-22 00:27:48.285789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-22 00:27:48.285987: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/cuda-11.2/lib64:/opt/intel/compilers_and_libraries_2020.0.166/linux/mkl/lib/intel64_lin:\n",
      "2021-11-22 00:27:48.286706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-11-22 00:27:48.286835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-11-22 00:27:48.286854: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-22 00:27:48.287815: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-22 00:27:48.287851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-22 00:27:48.287863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 18)        180       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 64, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 18)        2934      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 18)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 18)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 18)        72        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 36)        5868      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 36)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 36)        144       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 36)        11700     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 36)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 36)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 36)        144       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,201,148\n",
      "Trainable params: 1,200,932\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "[INFO] compiling model...\n",
      "/opt/conda/envs/liveness/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021-11-22 00:27:48.523321: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-22 00:27:48.524099: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3602185000 Hz\n",
      "87/87 [==============================] - 15s 164ms/step - loss: 1.4024 - accuracy: 0.5098 - val_loss: 0.7029 - val_accuracy: 0.4807\n",
      "Validation loss    : 0.702949047088623\n",
      "Validation accuracy: 0.4806866943836212\n",
      "2021-11-22 00:28:05.019496: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-481126471388/keras-liveness/training/training.npz\n",
      "s3://sagemaker-us-east-1-481126471388/keras-liveness/validation/validation.npz\n"
     ]
    }
   ],
   "source": [
    "#inputs = sagemaker_session.upload_data(path='data', bucket=bucket, key_prefix='data/cifar10')\n",
    "prefix = 'keras-liveness'\n",
    "\n",
    "#training_input_path   = sagemaker_session.upload_data('upload/training.npz', key_prefix=prefix+'/training')\n",
    "#validation_input_path = sagemaker_session.upload_data('upload/validation.npz', key_prefix=prefix+'/validation')\n",
    "training_input_path   = \"s3://sagemaker-us-east-1-481126471388/keras-liveness/training/training.npz\"\n",
    "validation_input_path = \"s3://sagemaker-us-east-1-481126471388/keras-liveness/validation/validation.npz\"\n",
    "print(training_input_path)\n",
    "print(validation_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for training \n",
    "Here is the full code for the network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_NUM_GPUS=1\n",
      "env: SM_MODEL_DIR=/tmp/model\n",
      "env: SM_CHANNEL_TRAINING=upload\n",
      "env: SM_CHANNEL_VALIDATION=upload\n",
      "env: AWS_PROFILE=default-api\n",
      "local_gpu sagemaker_execution\n"
     ]
    }
   ],
   "source": [
    "%env SM_NUM_GPUS=1\n",
    "%env SM_MODEL_DIR=/tmp/model\n",
    "%env SM_CHANNEL_TRAINING=upload\n",
    "%env SM_CHANNEL_VALIDATION=upload\n",
    "%env AWS_PROFILE=default-api\n",
    "#DUMMY_IAM_ROLE = 'arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-20200101T000001'\n",
    "print(instance_type, role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='train.py', \n",
    "#                          source_dir = './code',\n",
    "                          role=role,\n",
    "                          train_instance_count=1, \n",
    "#                           train_instance_type='local_gpu',\n",
    "                          train_instance_type='ml.m4.xlarge',\n",
    "                          framework_version='2.4.1',\n",
    "                          py_version='py37',\n",
    "                          script_mode=True,\n",
    "                          hyperparameters={'epochs': 1}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 3 µs, total: 13 µs\n",
      "Wall time: 29.6 µs\n",
      "2021-11-21 22:05:20 Starting - Starting the training job...\n",
      "2021-11-21 22:05:43 Starting - Launching requested ML instancesProfilerReport-1637532318: InProgress\n",
      "...\n",
      "2021-11-21 22:06:23 Starting - Preparing the instances for training............\n",
      "2021-11-21 22:08:24 Downloading - Downloading input data...\n",
      "2021-11-21 22:09:04 Training - Training image download completed. Training in progress..\u001b[34m2021-11-21 22:09:01.052933: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:01.058378: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:01.188005: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:05,126 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:05,133 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09,223 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09,243 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09,262 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09,276 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/model\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2021-11-21-22-05-17-428\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-11-21-22-05-17-428\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--model_dir\",\"s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 train.py --epochs 1 --model_dir s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/model\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09.440833: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09.440985: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09.472235: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 8, in <module>\n",
      "    import keras\u001b[0m\n",
      "\u001b[34mModuleNotFoundError: No module named 'keras'\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:11,493 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/usr/local/bin/python3.7 train.py --epochs 1 --model_dir s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/model\"\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09.440833: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09.440985: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-11-21 22:09:09.472235: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 8, in <module>\n",
      "    import keras\u001b[0m\n",
      "\u001b[34mModuleNotFoundError: No module named 'keras'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-11-21 22:09:27 Uploading - Uploading generated training model\n",
      "2021-11-21 22:09:27 Failed - Training job failed\n",
      "ProfilerReport-1637532318: Stopping\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job tensorflow-training-2021-11-21-22-05-17-428: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/local/bin/python3.7 train.py --epochs 1 --model_dir s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/model\"\n2021-11-21 22:09:09.440833: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n2021-11-21 22:09:09.440985: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n2021-11-21 22:09:09.472235: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\nTraceback (most recent call last):\n  File \"train.py\", line 8, in <module>\n    import keras\nModuleNotFoundError: No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f8156554a75c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalidation_input_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"jupyter.cell:done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/liveness/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/liveness/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/liveness/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3778\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3780\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/liveness/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3333\u001b[0m                 ),\n\u001b[1;32m   3334\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3335\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3336\u001b[0m             )\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job tensorflow-training-2021-11-21-22-05-17-428: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/local/bin/python3.7 train.py --epochs 1 --model_dir s3://sagemaker-us-east-1-481126471388/tensorflow-training-2021-11-21-22-05-17-428/model\"\n2021-11-21 22:09:09.440833: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n2021-11-21 22:09:09.440985: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n2021-11-21 22:09:09.472235: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\nTraceback (most recent call last):\n  File \"train.py\", line 8, in <module>\n    import keras\nModuleNotFoundError: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "%time\n",
    "tf_estimator.fit({'training': training_input_path, 'validation': validation_input_path})\n",
    "print (\"jupyter.cell:done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:liveness]",
   "language": "python",
   "name": "conda-env-liveness-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
